{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfile = open(\"data/file_parse_whole_data.txt\",\"w\",encoding=\"utf8\")\\npoc = 1\\nwith bz2.open(file_name, \"rb\") as f:\\n    for line in f.readlines().decode(\\'utf-8\\'):\\n        poc = poc + 1\\n        x = re.search(\"((={2,})( ?)(.*?)( ?)(={2,}))|<title>(.*)</title>\", line)\\n        y = re.search(\"\\\\(\\\\{\\\\{[Nn]o [Mm]ore [Ll]inks\\\\}\\\\}\\\\)\",x.group())\\n        if(y):\\n            continue\\n        if x.group(3) or x.group(5):\\n            k = x.group(2) + x.group(4) + x.group(6) + \"\\n\"\\n        else:\\n            k = x.group() + \"\\n\"\\n        file.write(k)\\n        if poc == 10:\\n            print(k)\\n        else:\\n            break\\n    \\nfile.close()'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#C:/Users/User/Desktop/enwiki-latest-pages-articles10.xml-p4045403p5399366.bz2\n",
    "file_name = \"C:/Users/User/Desktop/enwiki-latest-pages-articles.xml.bz2\"\n",
    "#file_name = \"C:/Users/User/Desktop/enwiki-latest-pages-articles10.xml-p4045403p5399366.bz2\"\n",
    "\n",
    "file = open(\"data/file_parse_whole_data.txt\",\"w\",encoding=\"utf8\")\n",
    "with bz2.open(file_name, \"rb\") as f:\n",
    "    content = f.readline().decode('utf-8')\n",
    "    while content:\n",
    "        x = re.search(\"((={2,})( ?)(.*?)( ?)(={2,}))|<title>(.*)</title>\", content)\n",
    "        if x:\n",
    "            y = re.search(\"\\(\\{\\{[Nn]o [Mm]ore [Ll]inks\\}\\}\\)\",x.group())\n",
    "            if y:\n",
    "                content = f.readline().decode('utf-8')\n",
    "                continue\n",
    "            if x.group(3) or x.group(5):\n",
    "                k = x.group(2) + x.group(4) + x.group(6) + \"\\n\"\n",
    "            else:\n",
    "                k = x.group() + \"\\n\"\n",
    "            file.write(k)\n",
    "        content = f.readline().decode('utf-8')\n",
    "file.close()\n",
    "\n",
    "\"\"\"\n",
    "file = open(\"data/file_parse_whole_data.txt\",\"w\",encoding=\"utf8\")\n",
    "poc = 1\n",
    "with bz2.open(file_name, \"rb\") as f:\n",
    "    for line in f.readlines().decode('utf-8'):\n",
    "        poc = poc + 1\n",
    "        x = re.search(\"((={2,})( ?)(.*?)( ?)(={2,}))|<title>(.*)</title>\", line)\n",
    "        y = re.search(\"\\(\\{\\{[Nn]o [Mm]ore [Ll]inks\\}\\}\\)\",x.group())\n",
    "        if(y):\n",
    "            continue\n",
    "        if x.group(3) or x.group(5):\n",
    "            k = x.group(2) + x.group(4) + x.group(6) + \"\\n\"\n",
    "        else:\n",
    "            k = x.group() + \"\\n\"\n",
    "        file.write(k)\n",
    "        if poc == 10:\n",
    "            print(k)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "file.close()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_section_headers(text, file):\n",
    "    for match in re.finditer(\"((={2,})( ?)(.*?)( ?)(={2,}))|<title>(.*)</title>\",text):\n",
    "        x = re.search(\"\\(\\{\\{[Nn]o [Mm]ore [Ll]inks\\}\\}\\)\",match.group())\n",
    "        if x:\n",
    "            continue\n",
    "        if match.group(3) or match.group(5):\n",
    "            k = match.group(2) + match.group(4) + match.group(6) + \"\\n\"\n",
    "        else:\n",
    "            k = match.group() + \"\\n\"\n",
    "        file.write(k)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_in_section(path):\n",
    "    img = \" ?\\[\\[File:[^\\]]+\\]\\]\"\n",
    "    x = re.search(img,path)\n",
    "    if x:\n",
    "        path = re.sub(img,\"\",path)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_linking(path):\n",
    "    #x = re.search(\"\\[\\[(.*)?\\|(.*)?\\]\\]|\\[\\[(.*)?\\]\\]\",path)\n",
    "    path = image_in_section(path)\n",
    "    for x in re.finditer(\"\\[\\[([^\\]]+)\\|([^\\]]+)\\]\\]|\\[\\[([^\\]]+)\\]\\]\",path):\n",
    "        if x:\n",
    "            if x.group(3):\n",
    "                path = re.sub(re.escape(x.group()), re.escape(x.group(3)),path)\n",
    "            elif x.group(2):\n",
    "                path = re.sub(re.escape(x.group()), re.escape(x.group(2)),path)\n",
    "   \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x, y):\n",
    "    z = x + \"\\t\" + y\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchy(text, file_headers):\n",
    "    for match in re.finditer(\"(={2,})(.*?)={2,}|<title>(.*)</title>\",text):\n",
    "        if match.group()[0] == \"<\":\n",
    "            title = match.group(3)\n",
    "            is_wiki_or_file = 0\n",
    "            if (len(re.findall(\"Wikipedia:|File:|Help:|Template:\",title)) > 0):\n",
    "                is_wiki_or_file = 1\n",
    "                continue\n",
    "            level = 0\n",
    "            path = title    \n",
    "        elif (is_wiki_or_file == 0):\n",
    "            if len(match.group(1)) > level:\n",
    "                temp = path\n",
    "                level = len(match.group(1))\n",
    "                path = add(match.group(0),path)\n",
    "                new_path = re.sub(\"=\",\"\",path);\n",
    "                #new_path = image_in_section(new_path)\n",
    "                new_path = delete_linking(new_path)\n",
    "                file_headers.write(new_path + \"\\n\")\n",
    "                #print(path + \"\\n\")\n",
    "\n",
    "            elif len(match.group(1)) == level:\n",
    "                path = add(match.group(0),temp)\n",
    "                new_path = re.sub(\"=\",\"\",path);\n",
    "                #new_path = image_in_section(new_path)\n",
    "                new_path = delete_linking(new_path)\n",
    "                file_headers.write(new_path + \"\\n\")\n",
    "                #print(path + \"\\n\")\n",
    "\n",
    "            else:\n",
    "                while(1):\n",
    "                    x = re.search(\"(={2,})(.*?)\\t\",temp)\n",
    "                    if x:\n",
    "                        if len(match.group(1)) <= len(x.group(1)):\n",
    "                            temp = temp[(x.end()):]\n",
    "                            if len(match.group(1)) == len(x.group(1)):\n",
    "                                break\n",
    "                        else:\n",
    "                            break\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "                level = len(match.group(1))\n",
    "                path = add(match.group(0),temp)\n",
    "                new_path = re.sub(\"=\",\"\",path);\n",
    "                #new_path = image_in_section(new_path)\n",
    "                new_path = delete_linking(new_path)\n",
    "                file_headers.write(new_path + \"\\n\")\n",
    "\n",
    "                #print(path + \"\\n\")\n",
    "\n",
    "    file_headers.close()          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_characters(file_unedit, text):\n",
    "    x = re.sub(\"\\'\\'\",\"\",text)\n",
    "    x = re.sub(\"&quot;\",\"\\\"\",x)\n",
    "    x = re.sub(\"&amp;\",\"&\",x)\n",
    "    x = re.sub(\"( ?\\{\\{[Aa]nchor ?\\|[^\\}]+\\}\\} ?|\\{\\{[Aa]nchor\\}\\})\",\"\",x)\n",
    "    x = re.sub(\"&lt;span(?:.*?)&gt;&lt;/span&gt; ?\",\"\",x)\n",
    "    #x = re.sub(\"&lt;ref(?:.*?)&lt;/ref&gt; ?\",\"\",x)\n",
    "    #x = re.sub(\"&lt;ref(?:.*?)/&gt; ?\",\"\",x)\n",
    "    x = re.sub(\"&lt;ref(?:.*?)(?:(/&gt;)|(&lt;/ref&gt;)) ?\",\"\",x)\n",
    "    x = re.sub(\"&lt;\\!--(?:.*?)--&gt; ?\",\"\",x)\n",
    "    x = re.sub(\"&lt;(?:sub|sup)&gt;(.*?)&lt;/(?:sub|sup)&gt;\",r'\\1',x)\n",
    "    x = re.sub(\"&lt;small&gt;(.*?)&lt;/small&gt;\",r'\\1',x)\n",
    "    x = re.sub(\"&lt;span(?:.*?)&gt;(.*?)&lt;/span&gt;\",r'\\1',x)\n",
    "    x = re.sub(\"{{rp\\|[^}]*}}\",\"\",x)\n",
    "    x = re.sub(\"&lt;u&gt;(.*?)&lt;/u&gt;\",r'\\1',x)\n",
    "    x = re.sub(\"&lt;center&gt;(.*?)&lt;/center&gt;\",r'\\1',x)\n",
    "    x = re.sub(\"&lt;big(?:.*?)&gt;(.*?)&lt;/big&gt;\",r'\\1',x)\n",
    "    x = re.sub(\"&lt;math&gt;(.*?)&lt;/math&gt;\",r'\\1',x)\n",
    "    x = re.sub(r\"^\\|(.*)\",\"\",x)\n",
    "    file_unedit.write(x)\n",
    "    file_unedit.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "with bz2.open(file_name, \"rb\") as f:\n",
    "    content = f.read().decode('utf-8')\n",
    "    \n",
    "file_parse_bigger_data = open(\"data/file_parse_bigger_data.txt\",\"w\",encoding=\"utf8\")\n",
    "find_section_headers(content, file_parse_bigger_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"data/file_parse_bigger_data.txt\", encoding=\"utf8\")\n",
    "text = file.read()\n",
    "file.close()\n",
    "\n",
    "file_headers = open(\"data/headers_bigger_data.txt\",\"w\",encoding=\"utf8\")\n",
    "hierarchy(text,file_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_unedited = open(\"data/headers_bigger_data.txt\", encoding=\"utf8\")\n",
    "text = file_unedited.read()\n",
    "file_unedited.close()\n",
    "\n",
    "file_edit = open(\"data/headers_bigger_data_edited.txt\",\"w\",encoding=\"utf8\")\n",
    "edit_characters(file_edit, text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"data/headers_bigger_data_edited.txt\", encoding=\"utf8\")\n",
    "text = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\iau\\lib\\site-packages\\elasticsearch\\connection\\base.py:190: ElasticsearchDeprecationWarning: [types removal] Specifying types in document index requests is deprecated, use the typeless endpoints instead (/{index}/_doc/{id}, /{index}/_doc, or /{index}/_create/{id}).\n",
      "  warnings.warn(message, category=ElasticsearchDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "poc = 1\n",
    "for i in text:\n",
    "    tmp = {\"section\":i}\n",
    "    es.index(index=\"section_headers\", doc_type=\"sections\", id=poc, body=tmp)\n",
    "    poc = poc + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = {\n",
    "    \"from\":0,\n",
    "    \"track_total_hits\": True,\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"section\":\"|titleArroyo\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "res = es.search(index=\"section_headers\", body=body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "972532"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'section': '|titleArroyo Seco |publisherSecretaría de Turismo de Querétaro |locationQuerétaro |languageSpanish |accessdateApril 14, 2011 |archive-urlhttps://web.archive.org/web/20111003190422/http://www.queretaro.travel/fichatecnica.aspx?qKP71rlORWRV6+73qOfunuQ\\tArroyo Seco, Querétaro\\n'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(res['hits']['hits'])):\n",
    "    print(res['hits']['hits'][i]['_source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_unedited = open(\"data/headers_bigger_data.txt\", encoding=\"utf8\")\n",
    "text = file_unedited.read()\n",
    "file_unedited.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_edit = open(\"data/headers_bigger_data_edited_2.txt\",\"w\",encoding=\"utf8\")\n",
    "edit_characters(file_edit, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"C:/Users/User/Desktop/file_parse_whole_data.txt\", encoding=\"utf8\")\n",
    "text = file.read()\n",
    "file.close()\n",
    "\n",
    "file_headers = open(\"data/headers_whole_data.txt\",\"w\",encoding=\"utf8\")\n",
    "hierarchy(text,file_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_unedited = open(\"data/headers_whole_data.txt\", encoding=\"utf8\")\n",
    "text = file_unedited.read()\n",
    "file_unedited.close()\n",
    "\n",
    "file_edit = open(\"data/headers_whole_data_edited.txt\",\"w\",encoding=\"utf8\")\n",
    "edit_characters(file_edit, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
