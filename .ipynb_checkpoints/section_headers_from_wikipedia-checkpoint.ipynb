{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing of titles and sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfile = open(\"data/file_parse_whole_data.txt\",\"w\",encoding=\"utf8\")\\npoc = 1\\nwith bz2.open(file_name, \"rb\") as f:\\n    for line in f.readlines().decode(\\'utf-8\\'):\\n        poc = poc + 1\\n        x = re.search(\"((={2,})( ?)(.*?)( ?)(={2,}))|<title>(.*)</title>\", line)\\n        y = re.search(\"\\\\(\\\\{\\\\{[Nn]o [Mm]ore [Ll]inks\\\\}\\\\}\\\\)\",x.group())\\n        if(y):\\n            continue\\n        if x.group(3) or x.group(5):\\n            k = x.group(2) + x.group(4) + x.group(6) + \"\\n\"\\n        else:\\n            k = x.group() + \"\\n\"\\n        file.write(k)\\n        if poc == 10:\\n            print(k)\\n        else:\\n            break\\n    \\nfile.close()'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#C:/Users/User/Desktop/enwiki-latest-pages-articles10.xml-p4045403p5399366.bz2\n",
    "file_name = \"C:/Users/User/Desktop/enwiki-latest-pages-articles.xml.bz2\"\n",
    "#file_name = \"C:/Users/User/Desktop/enwiki-latest-pages-articles10.xml-p4045403p5399366.bz2\"\n",
    "\n",
    "file = open(\"data/file_parse_whole_data.txt\",\"w\",encoding=\"utf8\")\n",
    "with bz2.open(file_name, \"rb\") as f:\n",
    "    content = f.readline().decode('utf-8')\n",
    "    while content:\n",
    "        x = re.search(\"((={2,})( ?)(.*?)( ?)(={2,}))|<title>(.*)</title>\", content)\n",
    "        if x:\n",
    "            y = re.search(\"\\(\\{\\{[Nn]o [Mm]ore [Ll]inks\\}\\}\\)\",x.group())\n",
    "            if y:\n",
    "                content = f.readline().decode('utf-8')\n",
    "                continue\n",
    "            if x.group(3) or x.group(5):\n",
    "                k = x.group(2) + x.group(4) + x.group(6) + \"\\n\"\n",
    "            else:\n",
    "                k = x.group() + \"\\n\"\n",
    "            file.write(k)\n",
    "        content = f.readline().decode('utf-8')\n",
    "file.close()\n",
    "\n",
    "\"\"\"\n",
    "file = open(\"data/file_parse_whole_data.txt\",\"w\",encoding=\"utf8\")\n",
    "poc = 1\n",
    "with bz2.open(file_name, \"rb\") as f:\n",
    "    for line in f.readlines().decode('utf-8'):\n",
    "        poc = poc + 1\n",
    "        x = re.search(\"((={2,})( ?)(.*?)( ?)(={2,}))|<title>(.*)</title>\", line)\n",
    "        y = re.search(\"\\(\\{\\{[Nn]o [Mm]ore [Ll]inks\\}\\}\\)\",x.group())\n",
    "        if(y):\n",
    "            continue\n",
    "        if x.group(3) or x.group(5):\n",
    "            k = x.group(2) + x.group(4) + x.group(6) + \"\\n\"\n",
    "        else:\n",
    "            k = x.group() + \"\\n\"\n",
    "        file.write(k)\n",
    "        if poc == 10:\n",
    "            print(k)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "file.close()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_section_headers(text, file):\n",
    "    for match in re.finditer(\"((={2,})( ?)(.*?)( ?)(={2,}))|<title>(.*)</title>\",text):\n",
    "        x = re.search(\"\\(\\{\\{[Nn]o [Mm]ore [Ll]inks\\}\\}\\)\",match.group())\n",
    "        if x:\n",
    "            continue\n",
    "        if match.group(3) or match.group(5):\n",
    "            k = match.group(2) + match.group(4) + match.group(6) + \"\\n\"\n",
    "        else:\n",
    "            k = match.group() + \"\\n\"\n",
    "        file.write(k)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_in_section(path):\n",
    "    img = \" ?\\[\\[File:[^\\]]+\\]\\]\"\n",
    "    x = re.search(img,path)\n",
    "    if x:\n",
    "        path = re.sub(img,\"\",path)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_linking(path):\n",
    "    #x = re.search(\"\\[\\[(.*)?\\|(.*)?\\]\\]|\\[\\[(.*)?\\]\\]\",path)\n",
    "    path = image_in_section(path)\n",
    "    for x in re.finditer(\"\\[\\[([^\\]]+)\\|([^\\]]+)\\]\\]|\\[\\[([^\\]]+)\\]\\]\",path):\n",
    "        if x:\n",
    "            if x.group(3):\n",
    "                path = re.sub(re.escape(x.group()), re.escape(x.group(3)),path)\n",
    "            elif x.group(2):\n",
    "                path = re.sub(re.escape(x.group()), re.escape(x.group(2)),path)\n",
    "   \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x, y):\n",
    "    z = x + \"\\t\" + y\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchy(text, file_headers):\n",
    "    for match in re.finditer(\"(={2,})(.*?)={2,}|<title>(.*)</title>\",text):\n",
    "        if match.group()[0] == \"<\":\n",
    "            title = match.group(3)\n",
    "            is_wiki_or_file = 0\n",
    "            if (len(re.findall(\"Wikipedia:|File:|Help:|Template:\",title)) > 0):\n",
    "                is_wiki_or_file = 1\n",
    "                continue\n",
    "            level = 0\n",
    "            path = title    \n",
    "        elif (is_wiki_or_file == 0):\n",
    "            if len(match.group(1)) > level:\n",
    "                temp = path\n",
    "                level = len(match.group(1))\n",
    "                path = add(match.group(0),path)\n",
    "                new_path = re.sub(\"=\",\"\",path);\n",
    "                #new_path = image_in_section(new_path)\n",
    "                new_path = delete_linking(new_path)\n",
    "                file_headers.write(new_path + \"\\n\")\n",
    "                #print(path + \"\\n\")\n",
    "\n",
    "            elif len(match.group(1)) == level:\n",
    "                path = add(match.group(0),temp)\n",
    "                new_path = re.sub(\"=\",\"\",path);\n",
    "                #new_path = image_in_section(new_path)\n",
    "                new_path = delete_linking(new_path)\n",
    "                file_headers.write(new_path + \"\\n\")\n",
    "                #print(path + \"\\n\")\n",
    "\n",
    "            else:\n",
    "                while(1):\n",
    "                    x = re.search(\"(={2,})(.*?)\\t\",temp)\n",
    "                    if x:\n",
    "                        if len(match.group(1)) <= len(x.group(1)):\n",
    "                            temp = temp[(x.end()):]\n",
    "                            if len(match.group(1)) == len(x.group(1)):\n",
    "                                break\n",
    "                        else:\n",
    "                            break\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "                level = len(match.group(1))\n",
    "                path = add(match.group(0),temp)\n",
    "                new_path = re.sub(\"=\",\"\",path);\n",
    "                #new_path = image_in_section(new_path)\n",
    "                new_path = delete_linking(new_path)\n",
    "                file_headers.write(new_path + \"\\n\")\n",
    "\n",
    "                #print(path + \"\\n\")\n",
    "\n",
    "    file_headers.close()          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_characters(file_unedit, text):\n",
    "    x = re.sub(\"\\'\\'\",\"\",text)\n",
    "    x = re.sub(\"&quot;\",\"\\\"\",x)\n",
    "    x = re.sub(\"&amp;\",\"&\",x)\n",
    "    x = re.sub(\"( ?\\{\\{[Aa]nchor ?\\|[^\\}]+\\}\\} ?|\\{\\{[Aa]nchor\\}\\})\",\"\",x)\n",
    "    x = re.sub(\"&lt;span(?:.*?)&gt;&lt;/span&gt; ?\",\"\",x)\n",
    "    #x = re.sub(\"&lt;ref(?:.*?)&lt;/ref&gt; ?\",\"\",x)\n",
    "    #x = re.sub(\"&lt;ref(?:.*?)/&gt; ?\",\"\",x)\n",
    "    x = re.sub(\"&lt;ref(?:.*?)(?:(/&gt;)|(&lt;/ref&gt;)) ?\",\"\",x)\n",
    "    x = re.sub(\"&lt;\\!--(?:.*?)--&gt; ?\",\"\",x)\n",
    "    x = re.sub(\"&lt;(?:sub|sup)&gt;(.*?)&lt;/(?:sub|sup)&gt;\",r'\\1',x)\n",
    "    x = re.sub(\"&lt;small&gt;(.*?)&lt;/small&gt;\",r'\\1',x)\n",
    "    x = re.sub(\"&lt;span(?:.*?)&gt;(.*?)&lt;/span&gt;\",r'\\1',x)\n",
    "    x = re.sub(\"{{rp\\|[^}]*}}\",\"\",x)\n",
    "    x = re.sub(\"&lt;u&gt;(.*?)&lt;/u&gt;\",r'\\1',x)\n",
    "    x = re.sub(\"&lt;center&gt;(.*?)&lt;/center&gt;\",r'\\1',x)\n",
    "    x = re.sub(\"&lt;big(?:.*?)&gt;(.*?)&lt;/big&gt;\",r'\\1',x)\n",
    "    x = re.sub(\"&lt;math&gt;(.*?)&lt;/math&gt;\",r'\\1',x)\n",
    "    x = re.sub(r\"^(\\|.*\\n)\",r\"\",x)\n",
    "    x = re.sub(r\"\\\\mathbf{(.*?)}\",r'\\1',x)\n",
    "    x = re.sub(r\"\\\\times\",\"×\",x)\n",
    "    x = re.sub(r\"\\{\\{math\\|(.*?)&lt;(.*?)\\}\\}\",r\"\\1<\\2\",x)\n",
    "    x = re.sub(r\"\\{\\{math\\|(.*?)&gt;(.*?)\\}\\}\",r\"\\1>\\2\",x)\n",
    "    x = re.sub(r\"\\{\\{sup\\|(.*?)\\}\\}\",r\"^(\\1)\",x)\n",
    "    x = re.sub(r\"\\{\\{sub\\|(.*?)\\}\\}\",r\"(\\1)\",x)\n",
    "    x = re.sub(r\"\\{\\{math\\|(.*?)\\}\\}\",r\"\\1\",x)\n",
    "    x = re.sub(r\"\\&sube;\",r\"⊆\",x)\n",
    "    x = re.sub(r\"\\{\\{mvar\\|(.*?)\\}\\}\",r\"\\1\",x)\n",
    "    x = re.sub(r\"\\{\\{[Vv]erify source\\|.*?\\}\\}\",r\"\",x)\n",
    "    x = re.sub(r\"\\&nu;\",r\"v\",x)\n",
    "    x = re.sub(r\"\\{\\{\\'\\}\\}\",r\"'\",x)\n",
    "    x = re.sub(r\"\\{\\{[Ww]hen\\|.*?\\}\\}\",r\"\",x)\n",
    "    x = re.sub(r\"\\{\\{[Ee]?[Nnm] ?dash\\}\\}\",r\"-\",x)\n",
    "    x = re.sub(r\"\\{\\{IPA\\|(.*?)\\}\\}\",r\"\\1\",x)\n",
    "    x = re.sub(r\"\\{\\{[Qq]uran-usc\\|([0-9]*)\\|([0-9]*)\\}\\}\",r\"Quran \\1:\\2\",x)\n",
    "    x = re.sub(r\"\\{\\{[Qq]uran-usc-range\\|([0-9]*)\\|([0-9]*)\\|?([0-9]*)?\\}\\}\",r\"Quran \\1:\\2\",x)\n",
    "    x = re.sub(r\"\\{\\{[Ll]ang\\|(?:.*?)\\|(.*?)\\}\\}\",r\"\\1\",x)\n",
    "    x = re.sub(r\"\\{\\{[Ll]ang-he-n\\|(.*?)\\}\\}\",r\"[\\1]\",x)\n",
    "    x = re.sub(r\"\\{\\{ct\\|(.*?)\\|[0-9]*\\}\\}\",r\"\\1\",x)\n",
    "    x = re.sub(r\"\\{\\{[Vv]isible anchor\\|(.*?)\\}\\}\",r\"\\1\",x)\n",
    "    x = re.sub(r\"\\{\\{pi\\}\\}\",r\"π\",x)\n",
    "    x = re.sub(r\"\\{\\{[Ff]b\\|(.*?)\\}\\}\",r\"\\1\",x)\n",
    "    x = re.sub(r\"\\(?\\{\\{[Nn]o ?[Mm]ore ?[Ll]inks ?\\}\\}.*\\n\",r\"\",x)\n",
    "    x = re.sub(r\"\\(\\{\\{Popular culture\\}\\}\\).*\\n\",r\"\",x)\n",
    "    x = re.sub(r\"\\(\\{\\{Sections\\}\\}\\).*\\n\",r\"\",x)\n",
    "    x = re.sub(r\"\\(\\{\\{Sections End\\}\\}\\).*\\n\",r\"\",x)\n",
    "    x = re.sub(r\"\\(\\{\\{NoMoreCruft\\}\\}\\).*\\n\",r\"\",x)\n",
    "    x = re.sub(r\"\\(\\{\\{Caution Links\\}\\}\\).*\\n\",r\"\",x)\n",
    "    x = re.sub(r\"\\{\\{circa\\|([0-9]*)\\}\\}\",r\"\\1\",x)\n",
    "    x = re.sub(r\"\\{\\{okina\\}\\}\",r\"'\",x)\n",
    "    x = re.sub(r\"\\{\\{chem\\|(.*?)\\|(.*?)\\}\\}\",r\"\\1 \\2\",x)\n",
    "    x = re.sub(r\"\\{\\{ref label(?:.*?)\\}\\}\",r\"\",x)\n",
    "    x = re.sub(r\"\\{\\{(spaced ndash|snd)\\}\\}\",r\" - \",x)\n",
    "    x = re.sub(r\"\\{\\{Relevance inline(?:.*?)\\}\\}\",r\"\",x)\n",
    "    x = re.sub(r\"\\{\\{refn(.*?)\\}\\}\",r\"\",x)\n",
    "    x = re.sub(r\"\\{\\{solution-inline(.*?)\\}\\}\",r\"\",x)\n",
    "    x = re.sub(r\"\\{\\{currentyear\\}\\}\",r\"2020\",x)\n",
    "    x = re.sub(r\"\\{\\{vague(?:.*?)\\}\\}\",r\"\",x)\n",
    "    x = re.sub(r\"\\{\\{fhw\\|(.*?)\\}\\}\",r\"\\1\",x)\n",
    "    x = re.sub(r\"\\{\\{ref\\|(?:.*?)\\}\\}\",r\"\",x)\n",
    "    x = re.sub(r\"\\{\\{[Ff]lag\\|(.*?)\\|(?:.*?)\\}\\}\",r\"\\1\",x)\n",
    "    x = re.sub(r\"\\{\\{vanchor\\|(.*?)\\}\\}\",r\"\\1\",x)\n",
    "    x = re.sub(r\"\\{\\{([A-Z]{3})\\}\\}\",r\"\\1\",x)\n",
    "    x = re.sub(r\"\\{\\{transl\\|(?:.*?)\\|(?:.*?)\\|(.*?)\\}\\}\",r\"\\1\",x)\n",
    "    x = re.sub(r\"\\{\\{frac\\|([0-9]*)\\|([0-9]*)\\|([0-9]*)\\}\\}\",r\"\\1 \\2/\\3\",x)\n",
    "    x = re.sub(r\"\\{\\{frac\\|([0-9]*)\\|([0-9]*)\\}\\}\",r\"\\1/\\2\",x)\n",
    "    x = re.sub(r\"\\{\\{nobold\\|(.*?)\\}\\}\",r\"\\1\",x)\n",
    "    x = re.sub(r\"\\{\\{fbu\\|[0-9]*\\|(.*?)\\}\\}\",r\"\\1\",x)\n",
    "    x = re.sub(r\"\\{\\{(?:[Cc]itation needed|Clarify|coord missing)\\|(?:.*?)\\}\\}\",r\"\",x)\n",
    "    x = re.sub(r\"\\{\\{white\\|(.*?)\\}\\}\",r\"\\1\",x)\n",
    "    x = re.sub(r\"\\{\\{(?:cr|small)\\|(.*?)\\}\\}\",r\"\\1\",x)\n",
    "    x = re.sub(r\"\\{\\{(MeSH number)\\|(.*?)\\|(.*?)\\}\\}\",r\"\\1 \\2\",x)\n",
    "    x = re.sub(r\"Module:User:Lesser Cartographies/MR\\n\",r\"\",x)\n",
    "    \n",
    "    file_unedit.write(x)\n",
    "    file_unedit.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "with bz2.open(file_name, \"rb\") as f:\n",
    "    content = f.read().decode('utf-8')\n",
    "    \n",
    "file_parse_bigger_data = open(\"data/file_parse_bigger_data.txt\",\"w\",encoding=\"utf8\")\n",
    "find_section_headers(content, file_parse_bigger_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"data/file_parse_bigger_data.txt\", encoding=\"utf8\")\n",
    "text = file.read()\n",
    "file.close()\n",
    "\n",
    "file_headers = open(\"data/headers_bigger_data.txt\",\"w\",encoding=\"utf8\")\n",
    "hierarchy(text,file_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_unedited = open(\"data/headers_bigger_data.txt\", encoding=\"utf8\")\n",
    "text = file_unedited.read()\n",
    "file_unedited.close()\n",
    "\n",
    "file_edit = open(\"data/headers_bigger_data_edited.txt\",\"w\",encoding=\"utf8\")\n",
    "edit_characters(file_edit, text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_unedited = open(\"data/headers_bigger_data.txt\", encoding=\"utf8\")\n",
    "text = file_unedited.read()\n",
    "file_unedited.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_edit = open(\"data/headers_bigger_data_edited_2.txt\",\"w\",encoding=\"utf8\")\n",
    "edit_characters(file_edit, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"C:/Users/User/Desktop/file_parse_whole_data.txt\", encoding=\"utf8\")\n",
    "text = file.read()\n",
    "file.close()\n",
    "\n",
    "file_headers = open(\"data/headers_whole_data.txt\",\"w\",encoding=\"utf8\")\n",
    "hierarchy(text,file_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time 6459.6161823272705\n"
     ]
    }
   ],
   "source": [
    "file_unedited = open(\"C:/Users/User/Desktop/headers_whole_data.txt\", encoding=\"utf8\")\n",
    "text = file_unedited.read()\n",
    "file_unedited.close()\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "file_edit = open(\"data/headers_whole_data_edited_final.txt\",\"w\",encoding=\"utf8\")\n",
    "edit_characters(file_edit, text)\n",
    "\n",
    "end = time.time()\n",
    "print (\"total time\", end-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time 344.00223755836487\n"
     ]
    }
   ],
   "source": [
    "file_edit = open(\"data/headers_whole_data_edited_final.txt\",encoding=\"utf8\")\n",
    "text_correction = file_edit.read()\n",
    "file_edit.close()\n",
    "\n",
    "st = time.time()\n",
    "file_correct = open(\"data/headers_whole_data_edited_final_correction.txt\", \"w\",encoding=\"utf8\")\n",
    "text_correction = re.sub(r\".*Module:User:Lesser.*\\n\",r\"\",text_correction)\n",
    "file_correct.write(text_correction)\n",
    "file_correct.close()\n",
    "end = time.time()\n",
    "print (\"total time\", end-st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole data indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data/headers_whole_data_edited_final_correction.txt\", encoding=\"utf8\")\n",
    "text = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexing(text, name_of_index):    \n",
    "    st = time.time()\n",
    "    tmp_list = []\n",
    "    count = 1\n",
    "    for i in text:\n",
    "        tmp = i.split(\"\\t\")\n",
    "        title = tmp[-1]\n",
    "        section = tmp[0]\n",
    "        hierarchy = i.replace(title,\"\")\n",
    "        actions = {\n",
    "                \"_index\": name_of_index,\n",
    "                \"_type\": \"doc\",\n",
    "                \"_id\": count,\n",
    "                \"_source\": {\n",
    "                    \"title\": title,\n",
    "                    \"section\": section,\n",
    "                    \"hierarchy\":hierarchy\n",
    "                    }\n",
    "              }\n",
    "        tmp_list.append(actions)\n",
    "        if (count % 100000 == 0):\n",
    "            helpers.bulk(es, tmp_list)\n",
    "            tmp_list.clear()\n",
    "        if (count % 1000000 == 0):\n",
    "            print(count)\n",
    "        count = count + 1   \n",
    "\n",
    "    if ((count-1) % 100000 != 0):\n",
    "        helpers.bulk(es, tmp_list)\n",
    "\n",
    "    end = time.time()\n",
    "    print (\"total time\", end-st)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\iau\\lib\\site-packages\\elasticsearch\\connection\\base.py:190: ElasticsearchDeprecationWarning: [types removal] Specifying types in bulk requests is deprecated.\n",
      "  warnings.warn(message, category=ElasticsearchDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "12000000\n",
      "13000000\n",
      "14000000\n",
      "15000000\n",
      "16000000\n",
      "17000000\n",
      "18000000\n",
      "19000000\n",
      "20000000\n",
      "21000000\n",
      "22000000\n",
      "23000000\n",
      "24000000\n",
      "25000000\n",
      "26000000\n",
      "27000000\n",
      "28000000\n",
      "29000000\n",
      "30000000\n",
      "total time 4084.5946564674377\n"
     ]
    }
   ],
   "source": [
    "indexing(text,\"all_data_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
